% SPDX-FileCopyrightText: 2024 Lukas Zirpel <thesis+lukas@zirpel.de>
% SPDX-License-Identifier: GPL-3.0-only

\chapter{Background and Related Work}
\label{chap:background}

\todo{There must be some analysis on WireGuard}
\todo{Split related work into separate chapter?}

In this section, we introduce the background necessary for executing this research project.
Furthermore, we review the related work to more clearly define the research gap, and leverage insights from that work alike.
For that, we first provide an overview of common censorship approaches.
Subsequently, we discuss various censorship evasion techniques.
Finally, we discuss related work in terms of censorship measurements and performance evaluation.

\section{Network data transmission and MTU}
Packet switched networks like the internet have a maximum packet size they can transport, called \textit{MTU} (Maximum Transmission Unit) \cite{wiki:Maximum_transmission_unit}.
Every link between two subsequent routers may have a different MTU.
The maximum size of a packet being transported along the path from one host to another is the minimum of the MTUs along the path.

When trying to send an IPv4 packet which is larger than the MTU, the packet is either fragmented (split into multiple smaller pieces) or if the DF (don't fragment) flag is set, it is dropped and an \textit{ICMP Destination Unreachable (Datagram Too Big)} message is sent back to the sender.
IPv6 does not support fragmentation by routers \cite{RFC2460}, so the packet is always dropped and an ICMP message sent in this case.

The current MTU along a certain path can be determined using \textit{Path MTU discovery} \cite{wiki:Path_MTU_Discovery}.
Unfortunately, some firewalls are configured to drop all ICMP packets for perceived security reasons, which breaks Path MTU discovery.
The Path MTU may also change (up or down) over time, which Path MTU discovery cannot account for.
In practice, the transport layer (protocol being transported as the IP payload) therefore needs to react to \textit{ICMP Datagram Too Big} messages anyways, which means that Path MTU discovery is not required for this application.
The link layer needs to be able to transport payloads of at least 68 bytes if it wants to allow transporting IPv4 packets.
For IPv6 this value is 1280 bytes large.

As using any form of encapsulation for tunneling adds overhead, the MTU inside of an IP tunnel (also called inner MTU or in-tunnel MTU) is always smaller than the MTU of the underlay (outer MTU / underlay MTU).
Since fragmentation has a relatively large performance overhead, this is usually avoided in practice.
For this reason, we also avoid fragmentation in this research by carefully choosing the MTU inside of the tunnels.
To avoid fragmentation, the inner MTU should equate to (or be less than) the outer MTU minus the protocol's overhead.


\section{Censorship}
\textit{Censorship} \cite{wiki:Censorship} is the suppression of information that is deemed objectionable, dangerous or "inconvenient" by governments or institutions.
\todo{cite \cite{wiki:Internet_censorship}}

\subsection{Preventing content access}
\todo{explain content access}

Since the Internet gained increasing relevance for information exchange in the general public, entities have investigated methods to inhibit information retrieval.[x]
From a technical perspective, censorship is not necessarily different than any other form of analyzing and preventing traffic flows, i.e., firewalling and deep packet inspection. [x]
The core difference is that for censorship, a state level actor determines semantically which network connections need to be prevented, i.e., based on the information or type of service that could be transported over the connection.[x]

The most simple version of censorship interferes with service discovery.
Here, the cannonical example are DNS blocklists.[x]
For DNS blocking, authorities communicate either FQDNs in the DNS, or full zones, which should not be discoverable by clients.
The DNS operator is then instructed to prevent correct IP lookups of the associated resource records.
Regularly, operators are also asked to, instead, redirect users trying to access these resources to, e.g., an informational page.

However, blocking by DNS operators can be easily circumvented [x] by seeking alternative DNS resolvers.

Since DNS blocking can be easily circumvented, censors now often also resort to network layer interference.
One of the simplest form is IP address blocking.
A list of IP addresses to block can be assembled by using the DNS to resolve unwanted domain names.
The downside of this relatively simple form of censorship is that multiple different websites may be hosted on one IP address and this technique would block all of them, even if the censor only intended to block one of them.

In response to the circumvention of DNS restrictions, censors may also block the standard DNS port (UDP and TCP port 53).
However, users adapt by utilizing non-standard ports \cite{dns-nonstandard-port} and encryption like DoT \cite{wiki:DNS_over_TLS} and DoH \cite{wiki:DNS_over_HTTPS}, making it difficult for censors to comprehensively block all potential avenues without causing significant collateral damage.

Censors escalate their efforts by targeting the IP addresses of known DNS servers.
This causes some collateral damage if these IPs host other services as well.
Users counteract this by employing proxies, VPNs, Tor, and other means, which tunnel traffic through other nodes.
These services are however also not immune to IP blocking.
For Tor for example, there exist public lists with IP addresses of all Tor relays.
Allowing legitimate users to discover the IP addresses of servers running these services, while not allowing the censors to do the same is a very challenging problem.

Advanced censors deploy active probing techniques to detect servers being used for circumvention.
This involves monitoring network traffic for patterns indicative of proxy or VPN usage.
Users respond by using encryption and developing sophisticated obfuscation methods.

Censors resort to deep packet inspection (DPI) techniques to identify specific websites from HTTP and HTTPS traffic.
By examining Host headers in HTTP or Server Name Indication (SNI) in HTTPS, they can block access to targeted domains.
Users counter this with domain fronting \cite{wiki:Domain_fronting}, masking their requests behind legitimate domains to avoid detection and with Encrypted Client Hello, where the TLS handshake and thus also SNI is encrypted.
As with DNS queries, users can also employ proxies, VPNs, Tor, and similar means to circumvent the censorship.

Without \textit{net neutrality} \cite{wiki:Net_neutrality}, many large internet service providers (ISPs) are inclined to treat portions of the traffic in special ways.
This situation shares a strong technical resemblance with censorship because both involve inspecting data packets and making decisions based on their content or source, albeit for different purposes.

As we saw, there are many possibilities of evading the censorship:

\subsection{Censorship evasion goals}
Depending on the threat model and local laws, the goal can be to just work around the censorship itself.
But since it may be illegal to circumvent the censorship in a country, it may also be desirable to avoid detection, which is much more difficult. \todo{this repeats the meaning of a sentence in the introduction}
The goal of not letting the censor know that the censorship was circumvented is related to the concept of \textit{anonymity} \cite{wiki:Anonymity}.
The latter hides the identity of a person, while the former hides that circumvention is happening.
With anonymity the adversaries may be various parties trying to identify the user, while censorship evasion specifically targets the censor's detection mechanisms.
\todo{cite \cite{wiki:Internet_censorship_circumvention}}

\section{Network Throughput Performance Measurements}
Network throughput is a measure of how much data can be transmitted over a given communication channel per time.
Every communication protocol has a certain overhead, including tunnel protocols, reducing the maximum possible useful network throughput called goodput.
Goodput can be influenced by many factors including every piece of hardware in the chain from one end of the communication to the other, protocol overhead, retransmissions due to packet loss and many more.

The authors of \textit{Promises and Potential of BBRv3} utilize a measurement setup somewhat similar to ours to evaluate BBRv3 \cite{Promises-and-Potential-of-BBRv3}.

\section{Reproducibility in Network Measurement}
Reproducibility \cite{wiki:Reproducibility} underpins the scientific method.
When a scientific study is reproducible, the findings of the study can be replicated by different researchers at any point in the future.

Achieving reproducibility is not easy, as there are many challenges.
One such challenge is that new versions of a software are released over time, which may behave differently than a previous version of the same software and could change the findings of the study.
A specific piece of software may also not be compatible with other software if they were released at significantly different times.
Special care needs to be taken to use the correct versions of all software (including dependencies) when trying to reproduce a study.
This is not trivial with most Linux distributions and package managers.
One way to resolve this problem is to distribute VM images with all the correct software installed along with the study, but VM images require a lot of storage space and have other problems and inconveniences.

Experimental systems also tend to accumulate state.
It is not clear if successive experiments start from the same state since a previous experiment run may have left behind some state that now influences the results.
\textit{Idempotence} \cite{wiki:Idempotence} in the context of running a computer science experiment refers to the experiment having the same outcome when running it multiple times in succession.
This is a desired and important property.
Stringent testing protocols and automation can bring a setup closer to idempotence or even reach it.
One possibility is to reboot all systems after each experiment and roll their state back to a known state, for example using filesystem snapshots.
\subsection{Nix}
\label{Nix-explanation}
Nix is a build system and package manager, which is inspired by functional programming principles.
It treats build steps as functions with the inputs being the dependencies (including source code) and build commands (or -recipe).
The outputs are the files produced by the build commands.
They are stored under a unique location in the filesystem, which includes a hash of all inputs in its name.
An output can never be changed after being created, as outputs are immutable (read-only).
Changing the build recipe, or any other input, causes a new output to be created with a new hash.
Nix goes to great lengths to try to ensure that the build step is pure, i.e., does not depend on inputs which were not declared.
This seems to work out pretty well, as over 90\% of all packages in the Nixpkgs repository are bitwise reproducible and over 99.7\% can be rebuilt \cite{malka:hal-04913007}.
A package not being bitwise reproducible is usually caused by it embedding information such as dates, the Linux kernel version, OS version, environment variables such as the number of available cores, or different kinds of randomness.
In practice, though, one does not usually recompile everything from source but rather uses the official binary cache.
This allows perfectly recreating our measurement setup, even if some packages are not perfectly reproducible.
While Nix cannot guarantee reproducibility, it does help a lot since it makes it easier to not accidentally depend on anything which is not declared as an input.

The Nix language (aka. Nixlang) is the domain-specific language (DSL) used by Nix.
\blockquote[\cite{nixlang}]{The Nix language is designed for conveniently creating and composing derivations â€“ precise descriptions of how contents of existing files are used to derive new files. It is a domain-specific, purely functional, lazily evaluated, dynamically typed programming language.}

\blockquote[\cite{nixlang}]{Nixpkgs [is] the largest, most up-to-date software distribution in the world, and written in the Nix language.}

NixOS is a Linux distribution built on Nix.
A single file written in the Nix language can fully declare all software and configuration of the system.
By using a lock file, the software and configuration can be recreated exactly.
NixOS uses Nix to build a single directory containing the entire operating system.
The directory is immutable, but a regular operating system is expected to be able to keep state.
For this reason, it also includes a so-called activation script, which essentially creates or changes a couple symbolic links to point to files or directories in that directory.
This includes \path{/etc} and all executable software available to users, which is stored in \path{/run/current-system/sw/bin}.
NixOS can boot with just two directories: \path{/boot} and \path{/nix} \cite{Erase_your_darlings}.
Everything else can be erased during a reboot to eliminate as much state as possible.
One method of achieving this is using a tmpfs, which stores all data in RAM and thus looses the data when shutting down the machine.
Another method is using ZFS or btrfs snapshots and rolling back to an empty snapshot while booting.
Opting in to keepig some state can be done per directory by storing the data on a different filesystem, ZFS dataset or btrfs subvolume.

Using NixOS and erasing the state on each reboot like this can be used to implement idempotent experiments.

The Nix ecosystem (specifically Nixpkgs) also includes a very powerful integration testing framework.
To use the NixOS testing framework, a setup and test script need to be declared.
The setup is declared in the Nix language and specifies one or more NixOS VM(s) and the network (VLANs) connecting them.
The test script is written in Python and can start and stop the VMs and execute commands.

Achieving reproducibility for performance measurements is especially tricky.
Not only the software needs to be reproduced as closely as possible, but also the hardware.

Ideally, the exact same hardware is used, but it may be difficult and expensive to aquire the exact same hardware.
As an alternative, employing similar hardware may yield sufficiently accurate measurements.


%%% Local Variables:
%%% TeX-master: "thesis"
%%% End:
